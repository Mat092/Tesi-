Appunti 

24/08/18

	ho scritto un programma che genera una popolazione casuale di reti, identificate da una lista di numeri da 1 a 100 che rappresenta 
gli hidden_layer della rete, la quale è effettivamente creata e utilizzata solo nella funzione che si occupa di calcolare il fitness dell'
individuo
Ciò è possibile grazie al codice fornito dalla libreria scikit_learn di python, in particolare dalla classe MLPClassifier.
Il programma poi si occupa di cercare la rete che possa raggiungere il punteggio più alto possibile nella classificazione di punti separati in 
due classi tramite metodi tipici degli algoritmi genetici, che mimano la selezione naturale ("survival of the fittest")
il fitness degli individui è misurato prima addestrandoli grazie alla funzione MLPClassifier.fit() e poi misurando il loro "score" nel 
riconoscimento delle due classi di punti su un set di dati diverso da quello di training.

Entrando in dettaglio, viene generato un set di dati chiamato "moons" da "sklearn.dataset.make_moons()" che restituisce i punti di due 
coordinat("X")e e la classe a cui appartengono ("y") in forma di array. Questi vengono separati in due parti, train e test, le quali fungeranno rispettivamente da addestramento e test per le reti
Per ora i dataset sono sempre uguali per ogni rete e per ogni generazione, tramite il "random_state" di make_moons sarebbe possibile cambiare 
di volta in volta il dataset.
Un' altra variabile da tenere in considerazione è il "noise" del dataset: un noise troppo alto sembra rendere impossibile all'algoritmo il
classificare ogni punto.

Dopodiche, si entra in un "while" che si ferma solo quando la rete "perfetta" (con fitness/score = 1.0) è trovata. Questa non è unica per 
dataset, nè DEVE essere la migliore: è possibile infatti trovare diverse reti con più o meno layer e più o meno neuroni che ottengono lo stesso
punteggio.

Alla prima generazione vengono subito calcolati i fitness dell'intera popolazione e questa viene ordinata in base allo score degli elementi 
tramite unn bubble_sort dal più alto al più basso. Sarebbe possibile ordinare le reti anche in base ad altri parametri (tipo il numero di 
neuroni e di layer, che inevitabilemente determinano anche il numero di collegamenti e pesi della rete) dato che è molto facile trovare reti
con punteggi uguali. In tal caso per ora la scelta è casuale, infatti le reti non vengono sposate in caso di fitness uguali. potremmo esplorare
famiglie di reti completamente diverse?
Viene inoltre stampata a schermo la rete migliore, insieme al fitness medio della popolazione.

La parte di programma con più difficoltà è quella che genera la generazione successiva, ed in particolare il modo di selezionare
i "genitori" della nuova popolazione. Ad ora viene assegnata una probabilità ad ogni elemento in abse al suo fitness, in particolare:

probabilità_individuo = (fitness_individuo) / (somma di tutti i fitness)

in questo modo la probabilità è normalizzata ad 1 e l'elemento con fitness più alto ha maggiore probabilità di essere scelto come genitore,
per mantenere (in parte) i suoi hidden_layer. È possibile che un individuo venga scelto 2 volte, come primo e secondo genitore, ma non sono
sicuro di questo passaggio.
Il metodo è chiamato "Roulette_wheel"(o almeno credo)

La funzione che genera in figli è "Crossover1", che taglia i due genomi genitori in parti differenti generando due interi casuali. Ad esempio:

rndint1 = 3
rndint2 = 2

genitore1 = [3,6,7,8,9]
genitore2 = [1,10,4,5]

figlio1 = [3,6,7,4,5]
figlio2 = [1,10,8,9]

i due figli saranno parte della nuova popolazione, che avrà lo stesso numero di individui della generazioen precedente.
Con questo metodo è possibile esplorare anche varie lunghezze di genoma, diverse dalle lunghezze iniziali dei genitori.

in seguito la popolazione appena creata viene sottoposta ad una mutazione casuale: ogni elemento ha il 10% di possibilià di essere allungato
o accorciato (con stessa probabilità) di un carattere casuale, ed il 10% di vedere un proprio layer modificato casualmente, mimando ciò che 
avviene in una mutazione casuale in natura.

la popolazione viene di nuovo valutata e ordinata di conseguenza e il ciclo ricomincia.


Come riferimenti per la teoria sulle reti neurali per ora ho il libro di Michael Nielsen "Neural Network e Deep learning", mentre per gli 
algoritmi genetici non ho ancora riferimenti precisi, ma mi sono affidato a wikipedia ed altri siti internet, almeno per quanto riguarda
gli algoritmi di base di questa logica.


25/08/18

	Il programma sembra funzionare, ho aumentato la percentuale di mutazione al 30%, perché troppo spesso si "fissa" su alcuni valori di
neuroni e li ripete per molte generazioni,anche su più layer, nonostante non siano particolarmente performanti.

ho implementato un diverso metodo di selezione più chiaro che non è molto diverso dal precedente ed ho risolto un altro errore logico 
del programma di cui non mi ero accorto precedentemente dovuto all' output di "range(len(stringa))" che era precedentemente
 "range(len(stringa)-1)" perchè pensavo che la prima versione sarebbe andata out of range in un ciclo "for"

Il primo individuo di ogni generazione mi sembra troppo avvantaggiato rispetto agli altri, ma ad ora non saprei come ovviare al problema
e comuqnue la scelta del primo rimane casuale, tuttavia nella selezione appare troppe volte, dalle prove eseguite succede spesso che sia 
l'unico selezionato per la generazione, finendo per essere l'unico genitore della generazione successiva, ciò non favorisce la diversità, ma 
la percentuale di mutazione unita al crossover casuale per ogni coppia di genitori sembrano ovviare al problema.
 
ho inserito la variabile "exclude", cosi che almeno il secondo genitore debba essere necessariamente diverso dal primo 

ho iniziato a implementare la libreria matplotlib per costruire qualche grafico di ciò che sta succedendo.

i grafici ottenebili fino ad'ora sono:

-frequenze relative di hidden layer 
-miglior fitness 	
-fitness medio	"in funzione della generazione"
-esempio della classificazione dei punti

Inoltre ora l'algoritmo si può fermare se non migliora il proprio score per alcune generazione O la rete rimane la stessa.

LIBRI:


http://www.boente.eti.br/fuzzy/ebook-fuzzy-mitchell.pdf   Melanie Mitchell - an introduction to genetic algorithm 
	-Baldwin Effect 67

http://citeseerx.ist.psu.edu/viewdoc/citations;jsessionid=ED993CF9D0BCBD42A73A265B77E5CC82?doi=10.1.1.44.5416 citeseer con genetic algorithm 

http://neuralnetworksanddeeplearning.com               michael nielsen- neural network and deep learning




Ho completamento cambiato il sistema di selezione per formare la nuova generazione: ora formo ogni coppia possibile di genitori 
e tramite lo stesso tipo di crossover i 200 sons, di questi seleziono i dieci migliori che formeranno la generazione succ.
Inoltre di generazione in generazione cambiano anche i dati di train e test con cui addestrare le reti.

ciò che noto è che spesso l'algoritmo sembra preferire le reti ad un layer nonostante poi questa nella classificazione finale non
ottengano dei gran punteggi, invece quando finisce per esplorare lunghezze più varie si ottengon risultati migliori:

""""""""""""""""""4 immagini significative di ciò"""""""""""""""

ho dovuto abilitare l'early_stopping nell'addestramento di ogni rete perchè altrimenti addestrare 200 reti era troppo lungo, inoltre ero in 
grado di classificare il dataset selezionato in 1 o 2 generazioni, senza avere alcuna evoluzione


in generale, l'algoritmo fa ciò che deve, ma in questo stato non sembra restituire grossi risultati, in particolare non sembra necessariamete 
"evolvere" verso una soluzione migliore.



















